{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ce5531-90a0-48c4-b6b8-f677c2c9af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, models, LoggingHandler, losses, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers.datasets import NoDuplicatesDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789fb799-f8f7-4ae5-b4a4-79e00d0b71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED 설정\n",
    "import random\n",
    "seed = 7777\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45a560d-a159-47a7-bdb2-e5e3a1ca8748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGGER 초기화\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    datefmt=\"%Y/%m/%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565d3153-1dbf-4ee3-a366-0fca08028e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'klue/roberta-base'\n",
    "nli_num_epochs = 1\n",
    "sts_num_epochs = 4\n",
    "train_batch_size = 32\n",
    "\n",
    "nli_model_save_path = 'output/training_nli_by_Softmaxloss'+pretrained_model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "sts_model_save_path = 'output/training_sts_by_Softmaxloss'+pretrained_model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d25b9f-276f-47c1-804e-8fe019b3570b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train :  24998\n"
     ]
    }
   ],
   "source": [
    "# load KLUE-NLI Dataset\n",
    "klue_nli_train = load_dataset(\"klue\", \"nli\", split='train')\n",
    "print('Length of Train : ',len(klue_nli_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6262c21-2d5c-4bc6-9eff-40423a408417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nli_input_example(dataset):\n",
    "    ''' \n",
    "    Transform to InputExample\n",
    "    ''' \n",
    "    input_examples = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        sentence1 = data['hypothesis']\n",
    "        sentence2 = data['premise']\n",
    "        label = data['label'] # 0(entailment), 1(neutral), 2(contradiction)\n",
    "        input_examples.append(InputExample(texts=[sentence1, sentence2], label=label))\n",
    "\n",
    "    return input_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e52565-7163-483d-8697-2820fff80643",
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_train_examples = make_nli_input_example(klue_nli_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb9e051-4303-4944-9d38-2520023d4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    nli_train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21101ea9-4da1-4226-9300-bf62c486b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:23:08 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load Embedding Model\n",
    "embedding_model = models.Transformer(\n",
    "    model_name_or_path=pretrained_model_name, \n",
    "    max_seq_length=256,\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "# Only use Mean Pooling -> Pooling all token embedding vectors of sentence.\n",
    "pooling_model = models.Pooling(\n",
    "    embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1a86a9-ba83-467c-a71d-62abc9acd77a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:23:08 - Softmax loss: #Vectors concatenated: 3\n",
      "2023/08/08 02:23:08 - Warmup-steps: 79\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008523702621459961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b50e4656c041bf87d03fe8b7413a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004990577697753906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 782,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cafbda9c405403faf992ee527b46aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:23:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 78 steps:\n",
      "2023/08/08 02:23:39 - Cosine-Similarity :\tPearson: 0.8331\tSpearman: 0.8476\n",
      "2023/08/08 02:23:39 - Manhattan-Distance:\tPearson: 0.8240\tSpearman: 0.8369\n",
      "2023/08/08 02:23:39 - Euclidean-Distance:\tPearson: 0.8224\tSpearman: 0.8355\n",
      "2023/08/08 02:23:39 - Dot-Product-Similarity:\tPearson: 0.7367\tSpearman: 0.7445\n",
      "2023/08/08 02:23:39 - Save model to output/training_nli_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:24:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 156 steps:\n",
      "2023/08/08 02:24:04 - Cosine-Similarity :\tPearson: 0.5904\tSpearman: 0.6869\n",
      "2023/08/08 02:24:04 - Manhattan-Distance:\tPearson: 0.6507\tSpearman: 0.6990\n",
      "2023/08/08 02:24:04 - Euclidean-Distance:\tPearson: 0.6451\tSpearman: 0.6978\n",
      "2023/08/08 02:24:04 - Dot-Product-Similarity:\tPearson: 0.5515\tSpearman: 0.5637\n",
      "2023/08/08 02:24:25 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 234 steps:\n",
      "2023/08/08 02:24:29 - Cosine-Similarity :\tPearson: 0.6189\tSpearman: 0.7038\n",
      "2023/08/08 02:24:29 - Manhattan-Distance:\tPearson: 0.6762\tSpearman: 0.7213\n",
      "2023/08/08 02:24:29 - Euclidean-Distance:\tPearson: 0.6690\tSpearman: 0.7198\n",
      "2023/08/08 02:24:29 - Dot-Product-Similarity:\tPearson: 0.5433\tSpearman: 0.5611\n",
      "2023/08/08 02:24:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 312 steps:\n",
      "2023/08/08 02:24:53 - Cosine-Similarity :\tPearson: 0.5580\tSpearman: 0.6523\n",
      "2023/08/08 02:24:53 - Manhattan-Distance:\tPearson: 0.6263\tSpearman: 0.6680\n",
      "2023/08/08 02:24:53 - Euclidean-Distance:\tPearson: 0.6186\tSpearman: 0.6662\n",
      "2023/08/08 02:24:53 - Dot-Product-Similarity:\tPearson: 0.5220\tSpearman: 0.5374\n",
      "2023/08/08 02:25:14 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 390 steps:\n",
      "2023/08/08 02:25:17 - Cosine-Similarity :\tPearson: 0.5975\tSpearman: 0.6906\n",
      "2023/08/08 02:25:17 - Manhattan-Distance:\tPearson: 0.6628\tSpearman: 0.7072\n",
      "2023/08/08 02:25:17 - Euclidean-Distance:\tPearson: 0.6537\tSpearman: 0.7053\n",
      "2023/08/08 02:25:17 - Dot-Product-Similarity:\tPearson: 0.5527\tSpearman: 0.5682\n",
      "2023/08/08 02:25:38 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 468 steps:\n",
      "2023/08/08 02:25:42 - Cosine-Similarity :\tPearson: 0.6307\tSpearman: 0.7083\n",
      "2023/08/08 02:25:42 - Manhattan-Distance:\tPearson: 0.6933\tSpearman: 0.7250\n",
      "2023/08/08 02:25:42 - Euclidean-Distance:\tPearson: 0.6845\tSpearman: 0.7237\n",
      "2023/08/08 02:25:42 - Dot-Product-Similarity:\tPearson: 0.5828\tSpearman: 0.5942\n",
      "2023/08/08 02:26:02 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 546 steps:\n",
      "2023/08/08 02:26:06 - Cosine-Similarity :\tPearson: 0.6308\tSpearman: 0.6974\n",
      "2023/08/08 02:26:06 - Manhattan-Distance:\tPearson: 0.6900\tSpearman: 0.7122\n",
      "2023/08/08 02:26:06 - Euclidean-Distance:\tPearson: 0.6848\tSpearman: 0.7113\n",
      "2023/08/08 02:26:06 - Dot-Product-Similarity:\tPearson: 0.5851\tSpearman: 0.5991\n",
      "2023/08/08 02:26:26 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 624 steps:\n",
      "2023/08/08 02:26:30 - Cosine-Similarity :\tPearson: 0.6450\tSpearman: 0.7100\n",
      "2023/08/08 02:26:30 - Manhattan-Distance:\tPearson: 0.7032\tSpearman: 0.7221\n",
      "2023/08/08 02:26:30 - Euclidean-Distance:\tPearson: 0.6975\tSpearman: 0.7213\n",
      "2023/08/08 02:26:30 - Dot-Product-Similarity:\tPearson: 0.6038\tSpearman: 0.6207\n",
      "2023/08/08 02:26:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 702 steps:\n",
      "2023/08/08 02:26:54 - Cosine-Similarity :\tPearson: 0.6449\tSpearman: 0.7108\n",
      "2023/08/08 02:26:54 - Manhattan-Distance:\tPearson: 0.7030\tSpearman: 0.7220\n",
      "2023/08/08 02:26:54 - Euclidean-Distance:\tPearson: 0.6966\tSpearman: 0.7209\n",
      "2023/08/08 02:26:54 - Dot-Product-Similarity:\tPearson: 0.6082\tSpearman: 0.6248\n",
      "2023/08/08 02:27:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 780 steps:\n",
      "2023/08/08 02:27:18 - Cosine-Similarity :\tPearson: 0.6333\tSpearman: 0.7017\n",
      "2023/08/08 02:27:18 - Manhattan-Distance:\tPearson: 0.6947\tSpearman: 0.7142\n",
      "2023/08/08 02:27:18 - Euclidean-Distance:\tPearson: 0.6878\tSpearman: 0.7131\n",
      "2023/08/08 02:27:18 - Dot-Product-Similarity:\tPearson: 0.5983\tSpearman: 0.6163\n",
      "2023/08/08 02:27:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2023/08/08 02:27:23 - Cosine-Similarity :\tPearson: 0.6333\tSpearman: 0.7016\n",
      "2023/08/08 02:27:23 - Manhattan-Distance:\tPearson: 0.6947\tSpearman: 0.7142\n",
      "2023/08/08 02:27:23 - Euclidean-Distance:\tPearson: 0.6878\tSpearman: 0.7131\n",
      "2023/08/08 02:27:23 - Dot-Product-Similarity:\tPearson: 0.5983\tSpearman: 0.6163\n"
     ]
    }
   ],
   "source": [
    "# Use SoftmaxLoss, because NLI is Multi-class Classification task.\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=model, \n",
    "    sentence_embedding_dimension=model.get_sentence_embedding_dimension(), \n",
    "    num_labels=3 # entailment, neutral, contradiction\n",
    ")\n",
    "\n",
    "# warmup steps\n",
    "warmup_steps = math.ceil(len(nli_train_examples) * nli_num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Training\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=dev_evaluator,\n",
    "    epochs=nli_num_epochs,\n",
    "    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=nli_model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1a374-750f-4a3c-8ec7-ebda8a7b9db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe1bba2-e28d-4958-b999-cf3c94219857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train :  10501\n",
      "Length of Valid :  1167\n",
      "Length of Test :  519\n"
     ]
    }
   ],
   "source": [
    "# load KLUE-STS Dataset\n",
    "klue_sts_train = load_dataset(\"klue\", \"sts\", split='train[:90%]')\n",
    "klue_sts_valid = load_dataset(\"klue\", \"sts\", split='train[-10%:]') # train의 10%를 validation set으로 사용\n",
    "klue_sts_test = load_dataset(\"klue\", \"sts\", split='validation')\n",
    "\n",
    "print('Length of Train : ',len(klue_sts_train))\n",
    "print('Length of Valid : ',len(klue_sts_valid))\n",
    "print('Length of Test : ',len(klue_sts_test))\n",
    "\n",
    "def make_sts_input_example(dataset):\n",
    "    ''' \n",
    "    Transform to InputExample\n",
    "    ''' \n",
    "    input_examples = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        sentence1 = data['sentence1']\n",
    "        sentence2 = data['sentence2']\n",
    "        score = (data['labels']['label']) / 5.0  # normalize 0 to 5\n",
    "        input_examples.append(InputExample(texts=[sentence1, sentence2], label=score))\n",
    "\n",
    "    return input_examples\n",
    "\n",
    "sts_train_examples = make_sts_input_example(klue_sts_train)\n",
    "sts_valid_examples = make_sts_input_example(klue_sts_valid)\n",
    "sts_test_examples = make_sts_input_example(klue_sts_test)\n",
    "\n",
    "# Train Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    sts_train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=train_batch_size,\n",
    ")\n",
    "\n",
    "# Evaluator by sts-validation\n",
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    sts_valid_examples,\n",
    "    name=\"sts-dev\",\n",
    ")\n",
    "\n",
    "# Evaluator by sts-test\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    sts_test_examples,\n",
    "    name=\"sts-test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "520d4ca8-7f60-4736-b22b-1eb9aca01672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:27:30 - Load pretrained SentenceTransformer: output/training_nli_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:27:32 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model of fine-tuning by NLI\n",
    "model = SentenceTransformer(nli_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e924b7c-4a2f-49b8-bd7e-975dd785e151",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:27:32 - Warmup-steps: 132\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006598234176635742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Epoch",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2332736e71ae4913b1c4ae56f346ea7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005875587463378906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 329,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814658a1391942489c88fa1772ae03ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:27:43 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 32 steps:\n",
      "2023/08/08 02:27:47 - Cosine-Similarity :\tPearson: 0.8871\tSpearman: 0.8798\n",
      "2023/08/08 02:27:47 - Manhattan-Distance:\tPearson: 0.8660\tSpearman: 0.8667\n",
      "2023/08/08 02:27:47 - Euclidean-Distance:\tPearson: 0.8655\tSpearman: 0.8664\n",
      "2023/08/08 02:27:47 - Dot-Product-Similarity:\tPearson: 0.8571\tSpearman: 0.8485\n",
      "2023/08/08 02:27:47 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:27:57 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 64 steps:\n",
      "2023/08/08 02:28:01 - Cosine-Similarity :\tPearson: 0.9245\tSpearman: 0.8981\n",
      "2023/08/08 02:28:01 - Manhattan-Distance:\tPearson: 0.9160\tSpearman: 0.8956\n",
      "2023/08/08 02:28:01 - Euclidean-Distance:\tPearson: 0.9160\tSpearman: 0.8958\n",
      "2023/08/08 02:28:01 - Dot-Product-Similarity:\tPearson: 0.9164\tSpearman: 0.8894\n",
      "2023/08/08 02:28:01 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:28:11 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 96 steps:\n",
      "2023/08/08 02:28:15 - Cosine-Similarity :\tPearson: 0.9392\tSpearman: 0.9049\n",
      "2023/08/08 02:28:15 - Manhattan-Distance:\tPearson: 0.9309\tSpearman: 0.9015\n",
      "2023/08/08 02:28:15 - Euclidean-Distance:\tPearson: 0.9309\tSpearman: 0.9021\n",
      "2023/08/08 02:28:15 - Dot-Product-Similarity:\tPearson: 0.9334\tSpearman: 0.8962\n",
      "2023/08/08 02:28:15 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:28:25 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 128 steps:\n",
      "2023/08/08 02:28:29 - Cosine-Similarity :\tPearson: 0.9451\tSpearman: 0.9092\n",
      "2023/08/08 02:28:29 - Manhattan-Distance:\tPearson: 0.9385\tSpearman: 0.9062\n",
      "2023/08/08 02:28:29 - Euclidean-Distance:\tPearson: 0.9383\tSpearman: 0.9065\n",
      "2023/08/08 02:28:29 - Dot-Product-Similarity:\tPearson: 0.9398\tSpearman: 0.8995\n",
      "2023/08/08 02:28:29 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:28:39 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 160 steps:\n",
      "2023/08/08 02:28:43 - Cosine-Similarity :\tPearson: 0.9512\tSpearman: 0.9128\n",
      "2023/08/08 02:28:43 - Manhattan-Distance:\tPearson: 0.9434\tSpearman: 0.9099\n",
      "2023/08/08 02:28:43 - Euclidean-Distance:\tPearson: 0.9431\tSpearman: 0.9096\n",
      "2023/08/08 02:28:43 - Dot-Product-Similarity:\tPearson: 0.9460\tSpearman: 0.9044\n",
      "2023/08/08 02:28:43 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:28:54 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 192 steps:\n",
      "2023/08/08 02:28:58 - Cosine-Similarity :\tPearson: 0.9526\tSpearman: 0.9111\n",
      "2023/08/08 02:28:58 - Manhattan-Distance:\tPearson: 0.9459\tSpearman: 0.9089\n",
      "2023/08/08 02:28:58 - Euclidean-Distance:\tPearson: 0.9459\tSpearman: 0.9093\n",
      "2023/08/08 02:28:58 - Dot-Product-Similarity:\tPearson: 0.9479\tSpearman: 0.9024\n",
      "2023/08/08 02:29:07 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 224 steps:\n",
      "2023/08/08 02:29:11 - Cosine-Similarity :\tPearson: 0.9561\tSpearman: 0.9145\n",
      "2023/08/08 02:29:11 - Manhattan-Distance:\tPearson: 0.9489\tSpearman: 0.9128\n",
      "2023/08/08 02:29:11 - Euclidean-Distance:\tPearson: 0.9487\tSpearman: 0.9129\n",
      "2023/08/08 02:29:11 - Dot-Product-Similarity:\tPearson: 0.9503\tSpearman: 0.9044\n",
      "2023/08/08 02:29:11 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:29:21 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 256 steps:\n",
      "2023/08/08 02:29:25 - Cosine-Similarity :\tPearson: 0.9575\tSpearman: 0.9159\n",
      "2023/08/08 02:29:25 - Manhattan-Distance:\tPearson: 0.9493\tSpearman: 0.9136\n",
      "2023/08/08 02:29:25 - Euclidean-Distance:\tPearson: 0.9491\tSpearman: 0.9134\n",
      "2023/08/08 02:29:25 - Dot-Product-Similarity:\tPearson: 0.9504\tSpearman: 0.9042\n",
      "2023/08/08 02:29:25 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:29:35 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 288 steps:\n",
      "2023/08/08 02:29:39 - Cosine-Similarity :\tPearson: 0.9585\tSpearman: 0.9140\n",
      "2023/08/08 02:29:39 - Manhattan-Distance:\tPearson: 0.9517\tSpearman: 0.9131\n",
      "2023/08/08 02:29:39 - Euclidean-Distance:\tPearson: 0.9515\tSpearman: 0.9132\n",
      "2023/08/08 02:29:39 - Dot-Product-Similarity:\tPearson: 0.9529\tSpearman: 0.9035\n",
      "2023/08/08 02:29:49 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 320 steps:\n",
      "2023/08/08 02:29:53 - Cosine-Similarity :\tPearson: 0.9602\tSpearman: 0.9202\n",
      "2023/08/08 02:29:53 - Manhattan-Distance:\tPearson: 0.9536\tSpearman: 0.9191\n",
      "2023/08/08 02:29:53 - Euclidean-Distance:\tPearson: 0.9537\tSpearman: 0.9195\n",
      "2023/08/08 02:29:53 - Dot-Product-Similarity:\tPearson: 0.9529\tSpearman: 0.9066\n",
      "2023/08/08 02:29:53 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:29:56 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2023/08/08 02:30:00 - Cosine-Similarity :\tPearson: 0.9595\tSpearman: 0.9183\n",
      "2023/08/08 02:30:00 - Manhattan-Distance:\tPearson: 0.9526\tSpearman: 0.9167\n",
      "2023/08/08 02:30:00 - Euclidean-Distance:\tPearson: 0.9527\tSpearman: 0.9173\n",
      "2023/08/08 02:30:00 - Dot-Product-Similarity:\tPearson: 0.9528\tSpearman: 0.9049\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004384279251098633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 329,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec150148fed445da01b53f7dd1c23f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:30:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 32 steps:\n",
      "2023/08/08 02:30:13 - Cosine-Similarity :\tPearson: 0.9594\tSpearman: 0.9187\n",
      "2023/08/08 02:30:13 - Manhattan-Distance:\tPearson: 0.9535\tSpearman: 0.9181\n",
      "2023/08/08 02:30:13 - Euclidean-Distance:\tPearson: 0.9535\tSpearman: 0.9185\n",
      "2023/08/08 02:30:13 - Dot-Product-Similarity:\tPearson: 0.9523\tSpearman: 0.9049\n",
      "2023/08/08 02:30:23 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 64 steps:\n",
      "2023/08/08 02:30:26 - Cosine-Similarity :\tPearson: 0.9600\tSpearman: 0.9202\n",
      "2023/08/08 02:30:26 - Manhattan-Distance:\tPearson: 0.9547\tSpearman: 0.9191\n",
      "2023/08/08 02:30:26 - Euclidean-Distance:\tPearson: 0.9546\tSpearman: 0.9192\n",
      "2023/08/08 02:30:26 - Dot-Product-Similarity:\tPearson: 0.9526\tSpearman: 0.9051\n",
      "2023/08/08 02:30:36 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 96 steps:\n",
      "2023/08/08 02:30:40 - Cosine-Similarity :\tPearson: 0.9601\tSpearman: 0.9217\n",
      "2023/08/08 02:30:40 - Manhattan-Distance:\tPearson: 0.9528\tSpearman: 0.9193\n",
      "2023/08/08 02:30:40 - Euclidean-Distance:\tPearson: 0.9528\tSpearman: 0.9191\n",
      "2023/08/08 02:30:40 - Dot-Product-Similarity:\tPearson: 0.9536\tSpearman: 0.9084\n",
      "2023/08/08 02:30:40 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:30:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 128 steps:\n",
      "2023/08/08 02:30:54 - Cosine-Similarity :\tPearson: 0.9599\tSpearman: 0.9238\n",
      "2023/08/08 02:30:54 - Manhattan-Distance:\tPearson: 0.9556\tSpearman: 0.9225\n",
      "2023/08/08 02:30:54 - Euclidean-Distance:\tPearson: 0.9555\tSpearman: 0.9222\n",
      "2023/08/08 02:30:54 - Dot-Product-Similarity:\tPearson: 0.9524\tSpearman: 0.9085\n",
      "2023/08/08 02:30:54 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:31:04 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 160 steps:\n",
      "2023/08/08 02:31:08 - Cosine-Similarity :\tPearson: 0.9604\tSpearman: 0.9199\n",
      "2023/08/08 02:31:08 - Manhattan-Distance:\tPearson: 0.9546\tSpearman: 0.9188\n",
      "2023/08/08 02:31:08 - Euclidean-Distance:\tPearson: 0.9546\tSpearman: 0.9188\n",
      "2023/08/08 02:31:08 - Dot-Product-Similarity:\tPearson: 0.9540\tSpearman: 0.9063\n",
      "2023/08/08 02:31:18 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 192 steps:\n",
      "2023/08/08 02:31:22 - Cosine-Similarity :\tPearson: 0.9605\tSpearman: 0.9209\n",
      "2023/08/08 02:31:22 - Manhattan-Distance:\tPearson: 0.9517\tSpearman: 0.9188\n",
      "2023/08/08 02:31:22 - Euclidean-Distance:\tPearson: 0.9516\tSpearman: 0.9184\n",
      "2023/08/08 02:31:22 - Dot-Product-Similarity:\tPearson: 0.9529\tSpearman: 0.9071\n",
      "2023/08/08 02:31:31 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 224 steps:\n",
      "2023/08/08 02:31:35 - Cosine-Similarity :\tPearson: 0.9611\tSpearman: 0.9229\n",
      "2023/08/08 02:31:35 - Manhattan-Distance:\tPearson: 0.9525\tSpearman: 0.9204\n",
      "2023/08/08 02:31:35 - Euclidean-Distance:\tPearson: 0.9524\tSpearman: 0.9200\n",
      "2023/08/08 02:31:35 - Dot-Product-Similarity:\tPearson: 0.9515\tSpearman: 0.9068\n",
      "2023/08/08 02:31:44 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 256 steps:\n",
      "2023/08/08 02:31:48 - Cosine-Similarity :\tPearson: 0.9607\tSpearman: 0.9215\n",
      "2023/08/08 02:31:48 - Manhattan-Distance:\tPearson: 0.9534\tSpearman: 0.9197\n",
      "2023/08/08 02:31:48 - Euclidean-Distance:\tPearson: 0.9534\tSpearman: 0.9197\n",
      "2023/08/08 02:31:48 - Dot-Product-Similarity:\tPearson: 0.9526\tSpearman: 0.9065\n",
      "2023/08/08 02:31:58 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 288 steps:\n",
      "2023/08/08 02:32:01 - Cosine-Similarity :\tPearson: 0.9622\tSpearman: 0.9241\n",
      "2023/08/08 02:32:01 - Manhattan-Distance:\tPearson: 0.9552\tSpearman: 0.9220\n",
      "2023/08/08 02:32:01 - Euclidean-Distance:\tPearson: 0.9551\tSpearman: 0.9219\n",
      "2023/08/08 02:32:01 - Dot-Product-Similarity:\tPearson: 0.9534\tSpearman: 0.9093\n",
      "2023/08/08 02:32:01 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:32:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 1 after 320 steps:\n",
      "2023/08/08 02:32:17 - Cosine-Similarity :\tPearson: 0.9612\tSpearman: 0.9216\n",
      "2023/08/08 02:32:17 - Manhattan-Distance:\tPearson: 0.9533\tSpearman: 0.9199\n",
      "2023/08/08 02:32:17 - Euclidean-Distance:\tPearson: 0.9532\tSpearman: 0.9198\n",
      "2023/08/08 02:32:17 - Dot-Product-Similarity:\tPearson: 0.9525\tSpearman: 0.9069\n",
      "2023/08/08 02:32:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 1:\n",
      "2023/08/08 02:32:23 - Cosine-Similarity :\tPearson: 0.9610\tSpearman: 0.9221\n",
      "2023/08/08 02:32:23 - Manhattan-Distance:\tPearson: 0.9535\tSpearman: 0.9204\n",
      "2023/08/08 02:32:23 - Euclidean-Distance:\tPearson: 0.9534\tSpearman: 0.9203\n",
      "2023/08/08 02:32:23 - Dot-Product-Similarity:\tPearson: 0.9524\tSpearman: 0.9079\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004149913787841797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 329,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa05d2e917e846e388df4b459549209c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:32:32 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 32 steps:\n",
      "2023/08/08 02:32:36 - Cosine-Similarity :\tPearson: 0.9621\tSpearman: 0.9241\n",
      "2023/08/08 02:32:36 - Manhattan-Distance:\tPearson: 0.9547\tSpearman: 0.9222\n",
      "2023/08/08 02:32:36 - Euclidean-Distance:\tPearson: 0.9546\tSpearman: 0.9221\n",
      "2023/08/08 02:32:36 - Dot-Product-Similarity:\tPearson: 0.9540\tSpearman: 0.9107\n",
      "2023/08/08 02:32:36 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:32:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 64 steps:\n",
      "2023/08/08 02:32:52 - Cosine-Similarity :\tPearson: 0.9614\tSpearman: 0.9235\n",
      "2023/08/08 02:32:52 - Manhattan-Distance:\tPearson: 0.9531\tSpearman: 0.9211\n",
      "2023/08/08 02:32:52 - Euclidean-Distance:\tPearson: 0.9530\tSpearman: 0.9210\n",
      "2023/08/08 02:32:52 - Dot-Product-Similarity:\tPearson: 0.9526\tSpearman: 0.9089\n",
      "2023/08/08 02:33:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 96 steps:\n",
      "2023/08/08 02:33:05 - Cosine-Similarity :\tPearson: 0.9623\tSpearman: 0.9246\n",
      "2023/08/08 02:33:05 - Manhattan-Distance:\tPearson: 0.9539\tSpearman: 0.9223\n",
      "2023/08/08 02:33:05 - Euclidean-Distance:\tPearson: 0.9539\tSpearman: 0.9225\n",
      "2023/08/08 02:33:05 - Dot-Product-Similarity:\tPearson: 0.9537\tSpearman: 0.9098\n",
      "2023/08/08 02:33:05 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:33:17 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 128 steps:\n",
      "2023/08/08 02:33:21 - Cosine-Similarity :\tPearson: 0.9626\tSpearman: 0.9249\n",
      "2023/08/08 02:33:21 - Manhattan-Distance:\tPearson: 0.9556\tSpearman: 0.9231\n",
      "2023/08/08 02:33:21 - Euclidean-Distance:\tPearson: 0.9557\tSpearman: 0.9232\n",
      "2023/08/08 02:33:21 - Dot-Product-Similarity:\tPearson: 0.9540\tSpearman: 0.9098\n",
      "2023/08/08 02:33:21 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:33:33 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 160 steps:\n",
      "2023/08/08 02:33:37 - Cosine-Similarity :\tPearson: 0.9622\tSpearman: 0.9229\n",
      "2023/08/08 02:33:37 - Manhattan-Distance:\tPearson: 0.9554\tSpearman: 0.9214\n",
      "2023/08/08 02:33:37 - Euclidean-Distance:\tPearson: 0.9554\tSpearman: 0.9214\n",
      "2023/08/08 02:33:37 - Dot-Product-Similarity:\tPearson: 0.9538\tSpearman: 0.9074\n",
      "2023/08/08 02:33:46 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 192 steps:\n",
      "2023/08/08 02:33:50 - Cosine-Similarity :\tPearson: 0.9623\tSpearman: 0.9231\n",
      "2023/08/08 02:33:50 - Manhattan-Distance:\tPearson: 0.9541\tSpearman: 0.9209\n",
      "2023/08/08 02:33:50 - Euclidean-Distance:\tPearson: 0.9541\tSpearman: 0.9208\n",
      "2023/08/08 02:33:50 - Dot-Product-Similarity:\tPearson: 0.9537\tSpearman: 0.9074\n",
      "2023/08/08 02:34:00 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 224 steps:\n",
      "2023/08/08 02:34:03 - Cosine-Similarity :\tPearson: 0.9632\tSpearman: 0.9252\n",
      "2023/08/08 02:34:03 - Manhattan-Distance:\tPearson: 0.9542\tSpearman: 0.9226\n",
      "2023/08/08 02:34:03 - Euclidean-Distance:\tPearson: 0.9542\tSpearman: 0.9224\n",
      "2023/08/08 02:34:03 - Dot-Product-Similarity:\tPearson: 0.9537\tSpearman: 0.9092\n",
      "2023/08/08 02:34:03 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:34:14 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 256 steps:\n",
      "2023/08/08 02:34:18 - Cosine-Similarity :\tPearson: 0.9627\tSpearman: 0.9251\n",
      "2023/08/08 02:34:18 - Manhattan-Distance:\tPearson: 0.9537\tSpearman: 0.9220\n",
      "2023/08/08 02:34:18 - Euclidean-Distance:\tPearson: 0.9537\tSpearman: 0.9218\n",
      "2023/08/08 02:34:18 - Dot-Product-Similarity:\tPearson: 0.9534\tSpearman: 0.9093\n",
      "2023/08/08 02:34:27 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 288 steps:\n",
      "2023/08/08 02:34:31 - Cosine-Similarity :\tPearson: 0.9634\tSpearman: 0.9267\n",
      "2023/08/08 02:34:31 - Manhattan-Distance:\tPearson: 0.9547\tSpearman: 0.9234\n",
      "2023/08/08 02:34:31 - Euclidean-Distance:\tPearson: 0.9547\tSpearman: 0.9235\n",
      "2023/08/08 02:34:31 - Dot-Product-Similarity:\tPearson: 0.9536\tSpearman: 0.9102\n",
      "2023/08/08 02:34:31 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:34:42 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 2 after 320 steps:\n",
      "2023/08/08 02:34:46 - Cosine-Similarity :\tPearson: 0.9637\tSpearman: 0.9269\n",
      "2023/08/08 02:34:46 - Manhattan-Distance:\tPearson: 0.9546\tSpearman: 0.9228\n",
      "2023/08/08 02:34:46 - Euclidean-Distance:\tPearson: 0.9548\tSpearman: 0.9231\n",
      "2023/08/08 02:34:46 - Dot-Product-Similarity:\tPearson: 0.9538\tSpearman: 0.9100\n",
      "2023/08/08 02:34:46 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:34:50 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 2:\n",
      "2023/08/08 02:34:54 - Cosine-Similarity :\tPearson: 0.9638\tSpearman: 0.9273\n",
      "2023/08/08 02:34:54 - Manhattan-Distance:\tPearson: 0.9549\tSpearman: 0.9233\n",
      "2023/08/08 02:34:54 - Euclidean-Distance:\tPearson: 0.9550\tSpearman: 0.9237\n",
      "2023/08/08 02:34:54 - Dot-Product-Similarity:\tPearson: 0.9537\tSpearman: 0.9102\n",
      "2023/08/08 02:34:54 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007098197937011719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 329,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e7dfb973164c65b8d558958937c679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:35:05 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 32 steps:\n",
      "2023/08/08 02:35:09 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9276\n",
      "2023/08/08 02:35:09 - Manhattan-Distance:\tPearson: 0.9563\tSpearman: 0.9247\n",
      "2023/08/08 02:35:09 - Euclidean-Distance:\tPearson: 0.9564\tSpearman: 0.9248\n",
      "2023/08/08 02:35:09 - Dot-Product-Similarity:\tPearson: 0.9546\tSpearman: 0.9111\n",
      "2023/08/08 02:35:09 - Save model to output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n",
      "2023/08/08 02:35:20 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 64 steps:\n",
      "2023/08/08 02:35:25 - Cosine-Similarity :\tPearson: 0.9638\tSpearman: 0.9275\n",
      "2023/08/08 02:35:25 - Manhattan-Distance:\tPearson: 0.9557\tSpearman: 0.9243\n",
      "2023/08/08 02:35:25 - Euclidean-Distance:\tPearson: 0.9558\tSpearman: 0.9245\n",
      "2023/08/08 02:35:25 - Dot-Product-Similarity:\tPearson: 0.9546\tSpearman: 0.9117\n",
      "2023/08/08 02:35:34 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 96 steps:\n",
      "2023/08/08 02:35:38 - Cosine-Similarity :\tPearson: 0.9635\tSpearman: 0.9262\n",
      "2023/08/08 02:35:38 - Manhattan-Distance:\tPearson: 0.9554\tSpearman: 0.9232\n",
      "2023/08/08 02:35:38 - Euclidean-Distance:\tPearson: 0.9556\tSpearman: 0.9235\n",
      "2023/08/08 02:35:38 - Dot-Product-Similarity:\tPearson: 0.9547\tSpearman: 0.9111\n",
      "2023/08/08 02:35:48 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 128 steps:\n",
      "2023/08/08 02:35:52 - Cosine-Similarity :\tPearson: 0.9635\tSpearman: 0.9260\n",
      "2023/08/08 02:35:52 - Manhattan-Distance:\tPearson: 0.9553\tSpearman: 0.9230\n",
      "2023/08/08 02:35:52 - Euclidean-Distance:\tPearson: 0.9554\tSpearman: 0.9232\n",
      "2023/08/08 02:35:52 - Dot-Product-Similarity:\tPearson: 0.9545\tSpearman: 0.9105\n",
      "2023/08/08 02:36:01 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 160 steps:\n",
      "2023/08/08 02:36:05 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9266\n",
      "2023/08/08 02:36:05 - Manhattan-Distance:\tPearson: 0.9557\tSpearman: 0.9240\n",
      "2023/08/08 02:36:05 - Euclidean-Distance:\tPearson: 0.9559\tSpearman: 0.9241\n",
      "2023/08/08 02:36:05 - Dot-Product-Similarity:\tPearson: 0.9548\tSpearman: 0.9109\n",
      "2023/08/08 02:36:14 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 192 steps:\n",
      "2023/08/08 02:36:18 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9270\n",
      "2023/08/08 02:36:18 - Manhattan-Distance:\tPearson: 0.9557\tSpearman: 0.9241\n",
      "2023/08/08 02:36:18 - Euclidean-Distance:\tPearson: 0.9558\tSpearman: 0.9241\n",
      "2023/08/08 02:36:18 - Dot-Product-Similarity:\tPearson: 0.9545\tSpearman: 0.9110\n",
      "2023/08/08 02:36:28 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 224 steps:\n",
      "2023/08/08 02:36:31 - Cosine-Similarity :\tPearson: 0.9638\tSpearman: 0.9266\n",
      "2023/08/08 02:36:32 - Manhattan-Distance:\tPearson: 0.9554\tSpearman: 0.9236\n",
      "2023/08/08 02:36:32 - Euclidean-Distance:\tPearson: 0.9555\tSpearman: 0.9236\n",
      "2023/08/08 02:36:32 - Dot-Product-Similarity:\tPearson: 0.9546\tSpearman: 0.9109\n",
      "2023/08/08 02:36:41 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 256 steps:\n",
      "2023/08/08 02:36:45 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9267\n",
      "2023/08/08 02:36:45 - Manhattan-Distance:\tPearson: 0.9553\tSpearman: 0.9237\n",
      "2023/08/08 02:36:45 - Euclidean-Distance:\tPearson: 0.9554\tSpearman: 0.9237\n",
      "2023/08/08 02:36:45 - Dot-Product-Similarity:\tPearson: 0.9546\tSpearman: 0.9110\n",
      "2023/08/08 02:36:55 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 288 steps:\n",
      "2023/08/08 02:36:58 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9267\n",
      "2023/08/08 02:36:58 - Manhattan-Distance:\tPearson: 0.9552\tSpearman: 0.9237\n",
      "2023/08/08 02:36:58 - Euclidean-Distance:\tPearson: 0.9553\tSpearman: 0.9237\n",
      "2023/08/08 02:36:58 - Dot-Product-Similarity:\tPearson: 0.9544\tSpearman: 0.9110\n",
      "2023/08/08 02:37:08 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 3 after 320 steps:\n",
      "2023/08/08 02:37:12 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9268\n",
      "2023/08/08 02:37:12 - Manhattan-Distance:\tPearson: 0.9553\tSpearman: 0.9237\n",
      "2023/08/08 02:37:12 - Euclidean-Distance:\tPearson: 0.9554\tSpearman: 0.9238\n",
      "2023/08/08 02:37:12 - Dot-Product-Similarity:\tPearson: 0.9545\tSpearman: 0.9111\n",
      "2023/08/08 02:37:15 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 3:\n",
      "2023/08/08 02:37:19 - Cosine-Similarity :\tPearson: 0.9640\tSpearman: 0.9268\n",
      "2023/08/08 02:37:19 - Manhattan-Distance:\tPearson: 0.9553\tSpearman: 0.9238\n",
      "2023/08/08 02:37:19 - Euclidean-Distance:\tPearson: 0.9554\tSpearman: 0.9238\n",
      "2023/08/08 02:37:19 - Dot-Product-Similarity:\tPearson: 0.9545\tSpearman: 0.9111\n"
     ]
    }
   ],
   "source": [
    "# Use CosineSimilarityLoss\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# warmup steps\n",
    "warmup_steps = math.ceil(len(sts_train_examples) * sts_num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Trainingㅁ\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=dev_evaluator,\n",
    "    epochs=sts_num_epochs,\n",
    "    evaluation_steps=int(len(train_dataloader)*0.1),\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=sts_model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1650fca6-a5a1-402e-94cd-a79fa9cda13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 02:37:19 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023/08/08 02:37:20 - Cosine-Similarity :\tPearson: 0.8855\tSpearman: 0.8874\n",
      "2023/08/08 02:37:20 - Manhattan-Distance:\tPearson: 0.8822\tSpearman: 0.8789\n",
      "2023/08/08 02:37:20 - Euclidean-Distance:\tPearson: 0.8832\tSpearman: 0.8803\n",
      "2023/08/08 02:37:20 - Dot-Product-Similarity:\tPearson: 0.8725\tSpearman: 0.8715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8873581486439149"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation sts-test\n",
    "test_evaluator(model, output_path=sts_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61732dac-015a-4bc0-999f-cd5fc8ec77d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba663878-14bb-4735-b700-17cf6cc70d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed_track_nm': 'Seasons (Feat. Harley Bird) (Futuristik & Whogaux Remix)', 'seed_track_artist_nm_list': ['Cadmium', 'Rival'], 'similar_track_nm': 'Seasons (Futuristik & Whogaux Remix)', 'similar_track_artist_nm_list': ['Cadmium', 'Harley Bird', 'Rival'], 'seed_track_nm_rnm': 'seasons', 'similar_track_nm_rnm': 'seasons'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "dset = []\n",
    "\n",
    "with open(\"cbf_track_names.json\") as fp:\n",
    "    for l in fp:\n",
    "        d = json.loads(l)\n",
    "        dset.append(d)\n",
    "\n",
    "print(dset[0])\n",
    "df = pd.DataFrame(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4618b19e-c05b-4c32-9e2e-219d58143414",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "a= pd.read_parquet('./dataset.parquet')\n",
    "a['track_id']= a['track_id'].astype('str')\n",
    "a['string']=a['track_nm']+' '+a['artist_nm_list']\n",
    "a= a.set_index(np.arange(len(a)))\n",
    "b = a.sample(frac=1).reset_index(drop=True)\n",
    "original = a['string'].values\n",
    "similar = b['string'].values\n",
    "new_df=pd.DataFrame({'sentence1':original, 'sentence2':similar,'label':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285fe150-8252-4e8f-a70e-6b946f02dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_parquet('rep_track.parquet')\n",
    "file1 = file1.set_index(np.arange(len(file1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbc63832-64da-46c8-abe7-98bcc25fd10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['similar_track_id', 'similar_track_nm', 'similar_track_nm_notbrac',\n",
       "       'similar_track_nm_notspace', 'similar_track_nm_notbracspace',\n",
       "       'similar_artist_ids', 'similar_track_nm_origin', 'track_id',\n",
       "       'rep_track_id', 'track_nm', 'track_nm_notbrac', 'track_nm_notspace',\n",
       "       'track_nm_notbracspace', 'artist_ids', 'track_nm_origin',\n",
       "       'notspace_distance', 'notbracspace_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b2799595-200c-4f14-a7c1-e5fc41c417e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'sentence1':file1['track_nm_notbrac'], 'sentence2':file1['similar_track_nm_notbrac'],'label':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "49c93c4f-e628-48e8-aafd-0deb01ea55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = []\n",
    "sentence2 = []\n",
    "labels = []\n",
    "for i in range(len(new_df)):\n",
    "    sentence1.append(new_df['sentence1'][i])\n",
    "    sentence2.append(new_df['sentence2'][i])\n",
    "    labels.append(new_df['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f581418b-6046-4687-9094-c41878456a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "68edd56a-fc7e-498d-8586-40e10392e16b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/08/08 06:31:51 - Load pretrained SentenceTransformer: output/training_sts_by_Softmaxlossklue-roberta-base-2023-08-08_02-22-25\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006909847259521484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batches",
       "rate": null,
       "total": 28191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d36656bfd545c8bb239a89dbb98222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004691600799560547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Batches",
       "rate": null,
       "total": 28191,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a96897bbe24412daab1bacbf1491c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/28191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.58 GiB (GPU 2; 79.10 GiB total capacity; 5.58 GiB already allocated; 775.94 MiB free; 5.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(sts_model_save_path,device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m      3\u001b[0m corpus_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(sentence1, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# senetence1 유사도\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# sentence2 유사도\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcosine_similarity_manual\u001b[39m(x, y, small_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m): \u001b[38;5;66;03m# sentence1과 sentence2의 임베딩값으로 유사도 계산\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     result \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mdot(x, y) \u001b[38;5;241m/\u001b[39m (torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(x) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(y) \u001b[38;5;241m+\u001b[39m small_number)\n",
      "File \u001b[0;32m/opt/conda/envs/kobert/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:195\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    192\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_tensor:\n\u001b[0;32m--> 195\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m    197\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 2; 79.10 GiB total capacity; 5.58 GiB already allocated; 775.94 MiB free; 5.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(sts_model_save_path,device = device)\n",
    "\n",
    "corpus_embeddings = model.encode(sentence1, convert_to_tensor=True) # senetence1 유사도\n",
    "query_embeddings = model.encode(sentence2, convert_to_tensor=True) # sentence2 유사도\n",
    "\n",
    "def cosine_similarity_manual(x, y, small_number=1e-8): # sentence1과 sentence2의 임베딩값으로 유사도 계산\n",
    "    result =  torch.dot(x, y) / (torch.linalg.norm(x) * torch.linalg.norm(y) + small_number)\n",
    "    return result\n",
    "\n",
    "test_scores = []\n",
    "for i in range(len(sentence1)):\n",
    "    score = cosine_similarity_manual(corpus_embeddings[i],query_embeddings[i])\n",
    "    score=score.cpu().detach().numpy()\n",
    "    test_scores.append(score)\n",
    "\n",
    "test_scores = np.array(test_scores) # 모델 예측값\n",
    "y_pred = np.where(test_scores>=0.6, 1, 0) # klue에서 3.0을 기준으로 binary label을 만들었기에, normalize 기준 threshold: 0.6\n",
    "labels = np.array(labels)\n",
    "y_label = np.where(labels >= 0.6, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34b026-6d92-49df-96db-81eaccbd690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = corpus_embeddings.cpu().detach().numpy()\n",
    "query_embeddings = query_embeddings.cpu().detach().numpy()\n",
    "\n",
    "cosine_scores = 1 - (paired_cosine_distances(corpus_embeddings, query_embeddings))\n",
    "manhattan_distances = -paired_manhattan_distances(corpus_embeddings, query_embeddings)\n",
    "euclidean_distances = -paired_euclidean_distances(corpus_embeddings, query_embeddings)\n",
    "dot_products = [np.dot(emb1, emb2) for emb1, emb2 in zip(corpus_embeddings, query_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fce606-f364-4284-b6ac-d86190c24adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff19eed-d995-4fa5-b987-d2b3d01aa1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['sentence_bert_notblac_label']= cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3039e02a-59bf-4ebc-be9d-1c5fc49f1fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_bert_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26432</th>\n",
       "      <td>Love Somebody Maroon 5</td>\n",
       "      <td>What Lovers Do Maroon 5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38914</th>\n",
       "      <td>Snowman J.Fla</td>\n",
       "      <td>Snowman Sia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43413</th>\n",
       "      <td>Burning Thursdz Burning Thursday</td>\n",
       "      <td>Burning Thursdah Burning Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88338</th>\n",
       "      <td>Won't Bite (Explicit Ver.) Doja Cat,Smino</td>\n",
       "      <td>JACKBOYS (Explicit Ver.) JACKBOYS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101580</th>\n",
       "      <td>Cry In My Gucci (Explicit Ver.) Margaret</td>\n",
       "      <td>You (Explicit Ver.) The 1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122111</th>\n",
       "      <td>Too Deep (Explicit Ver.) Kehlani</td>\n",
       "      <td>How (Explicit Ver.) Ella Mai</td>\n",
       "      <td>0</td>\n",
       "      <td>0.722489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170480</th>\n",
       "      <td>Deepnb Deepnoid</td>\n",
       "      <td>Deepu Deepnoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185948</th>\n",
       "      <td>Abracadabra (Explicit Ver.) Nas</td>\n",
       "      <td>Blah Blah Blah (Explicit Ver.) Kesha</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207041</th>\n",
       "      <td>꼭두각시 핑크퐁 (Pinkfong)</td>\n",
       "      <td>프리도를 따라 해 핑크퐁 (Pinkfong)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.710193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255369</th>\n",
       "      <td>Level of Concern Twenty One Pilots</td>\n",
       "      <td>Never Take It Twenty One Pilots</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278372</th>\n",
       "      <td>La Isla Bonita Madonna</td>\n",
       "      <td>Echo Olivia Dean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292453</th>\n",
       "      <td>ILoveUIHateU (Explicit Ver.) Playboi Carti</td>\n",
       "      <td>Panic Emoji (Explicit Ver.) JPEGMAFIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293489</th>\n",
       "      <td>숙면 감성태교 멜로디 (자장가) 자장가 베이비</td>\n",
       "      <td>신생아 자장가 멜로디 자장가 베이비</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence1   \n",
       "26432                       Love Somebody Maroon 5  \\\n",
       "38914                                Snowman J.Fla   \n",
       "43413             Burning Thursdz Burning Thursday   \n",
       "88338    Won't Bite (Explicit Ver.) Doja Cat,Smino   \n",
       "101580    Cry In My Gucci (Explicit Ver.) Margaret   \n",
       "122111            Too Deep (Explicit Ver.) Kehlani   \n",
       "170480                             Deepnb Deepnoid   \n",
       "185948             Abracadabra (Explicit Ver.) Nas   \n",
       "207041                         꼭두각시 핑크퐁 (Pinkfong)   \n",
       "255369          Level of Concern Twenty One Pilots   \n",
       "278372                      La Isla Bonita Madonna   \n",
       "292453  ILoveUIHateU (Explicit Ver.) Playboi Carti   \n",
       "293489                   숙면 감성태교 멜로디 (자장가) 자장가 베이비   \n",
       "\n",
       "                                    sentence2  label  sentence_bert_label  \n",
       "26432                 What Lovers Do Maroon 5      0             0.777964  \n",
       "38914                             Snowman Sia      0             0.803596  \n",
       "43413       Burning Thursdah Burning Thursday      0             0.975578  \n",
       "88338       JACKBOYS (Explicit Ver.) JACKBOYS      0             0.727241  \n",
       "101580           You (Explicit Ver.) The 1975      0             0.713326  \n",
       "122111           How (Explicit Ver.) Ella Mai      0             0.722489  \n",
       "170480                         Deepu Deepnoid      0             0.928830  \n",
       "185948   Blah Blah Blah (Explicit Ver.) Kesha      0             0.775345  \n",
       "207041               프리도를 따라 해 핑크퐁 (Pinkfong)      0             0.710193  \n",
       "255369        Never Take It Twenty One Pilots      0             0.731473  \n",
       "278372                       Echo Olivia Dean      0             0.712885  \n",
       "292453  Panic Emoji (Explicit Ver.) JPEGMAFIA      0             0.706070  \n",
       "293489                    신생아 자장가 멜로디 자장가 베이비      0             0.747291  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['sentence_bert_label']>=0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cddf7b-80ac-4a6a-a10d-2200869ecd9d",
   "metadata": {},
   "source": [
    "import os\n",
    "lst_file= os.listdir('data/')\n",
    "file1=pd.read_parquet(f'./data/{lst_file[0]}')\n",
    "for i in range(1,len(lst_file)):\n",
    "    file2 = pd.read_parquet(f'./data/{lst_file[i]}')\n",
    "    file1 = pd.concat([file1,file2])\n",
    "file1.to_parquet('rep_track.parquet', compression='gzip')\n",
    "file1=file1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb9239-39a3-4825-bc08-98108db0aea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kobert",
   "language": "python",
   "name": "kobert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
